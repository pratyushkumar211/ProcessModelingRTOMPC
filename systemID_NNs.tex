\documentclass{article}
\usepackage[total={4.5in, 8in}]{geometry}
%% The graphicx and color packages should give you all the color, % figure
%inclusion, and text/figure resizing capabilities you need.
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz,tikzsettings,bm}
\usepackage{almostfull}

\definecolor{pblue}{HTML}{1F77B4}
\definecolor{pgold}{HTML}{FF7f0E}
\definecolor{pgreen}{HTML}{2CA02C}
\definecolor{pred}{HTML}{D62728}
\definecolor{ppurple}{HTML}{9467BD}
\definecolor{ppink}{HTML}{E377C2}
\definecolor{pyellow}{HTML}{BCBD22}
\definecolor{pcyan}{HTML}{17BECF}

\usepackage{authblk}

%% You should not need more than this for fancy math.
\usepackage{amsmath}   % Extra math commands and environments from the AMS
\usepackage{amssymb}   % Special symbols from the AMS
\usepackage{amsthm}    % Enhanced theorem and proof environments from the AMS
\usepackage{latexsym}  % A few extra LaTeX symbols
\usepackage{cleveref}
\usepackage{lucidbry}
\input{stanacce}
\renewcommand{\baselinestretch}{1.0666}

%% The URL package is handy for typesetting URLs.  It does not define % an
%\email command because so many document styles already do that. % So we define
%one here that uses a typewriter font.
\usepackage{url}
%\DeclareRobustCommand{\email}{\begingroup \urlstyle{tt}\Url}
\providecommand{\email}{}
\renewcommand{\email}[1]{\texttt{#1}}

%% This provides various customized verbatim commands and % environments.  You
%probably don't need it.
\usepackage{fancyvrb}
\DefineShortVerb{\|} \VerbatimFootnotes
\DefineVerbatimEnvironment{code}{Verbatim}{%
  frame=single, framesep=1em, xleftmargin=1em, xrightmargin=1em, samepage=true,
  fontsize=\footnotesize}
\usepackage{upquote}

%% Your document may require a different bibliography style.  I've % come to
%prefer Author (YYYY) styles because it makes it easier for % a person who knows
%something about the literature to understand % what is being cited without
%having to skip to the list of % references.
\usepackage[authoryear,round,longnamesfirst]{natbib}

%% You won't normally need this definition in your documents, but it % is here
%so we can typeset the BibTeX logo correctly.
\makeatletter
\@ifundefined{BibTeX} {\def\BibTeX{{\rmfamily B\kern-.05em%
    \textsc{i\kern-.025em b}\kern-.08em%
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}}{}

\def\blfootnote{\xdef\@thefnmark{}\@footnotetext}
\makeatother

%% Allow more of the pages to be occupied by graphs.  These parameters % are
%described in section c.9.1 of the LaTeXbook.  Your document may % not benefit
%from these parameters (it could make things worse) so % you should only change
%these from the defaults if you need to.
\setcounter{topnumber}{2}              %% 2
\setcounter{bottomnumber}{1}           %% 1
\setcounter{totalnumber}{3}            %% 3
\renewcommand{\topfraction}{0.9}       %% 0.7
\renewcommand{\bottomfraction}{0.9}    %% 0.3
\renewcommand{\textfraction}{0.1}      %% 0.2
\renewcommand{\floatpagefraction}{.7}  %% 0.5
\newlength{\graphwidth}
\setlength{\graphwidth}{0.8\columnwidth}

\usepackage{subfiles}

\graphicspath{{./}{./figures/}{./figures/paper/}}

\newcommand{\Is}{\bm{\mathrm{I}}} % Resources.
\newcommand{\Js}{\bm{\mathrm{J}}} % Units.
\newcommand{\Ks}{\bm{\mathrm{K}}} % Resources.
\newcommand{\Ms}{\bm{\mathrm{M}}} % Transition catalog.
\newcommand{\Ns}{\bm{\mathrm{N}}} % Transition counter.

\newcommand{\useq}{\mathbf{u}} \newcommand{\xseq}{\mathbf{x}}
\newcommand{\bbR}{\mathbb{R}} \newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbU}{\mathbb{U}} \newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbX}{\mathbb{X}} \newcommand{\bbP}{\mathbb{P}}

\title{Hybrid nonlinear system identification using neural networks}
\author{Pratyush Kumar}
\date{\today}

\begin{document}

\maketitle

\section{Process modeling}
Consider a nonlinear plant evolving in continuous time as
\begin{align*}
  \dot{x}_p &= f_p(x_p, u, w) \\
  y &= h_p(x_p) + v
\end{align*}
in which $x_p \in \bbR^{n_p}$ is the plant state, $u \in \bbU$ is the
manipulated control input, $y \in \bbR^p$ is the measurement, $w$ is the process
noise, and $v$ is the measurement noise.

\subsection{Completion of the u-y model}
We assume that grey-box modeling is performed for the plant, and we wish to
augment the grey-box model with neural networks for improvement in the accuracy
of the model. From first-principles modeling, we have the following grey-box
model in continuous time
\begin{align*}
  \dot{x}_g &= f_g(x_g, u) \\
  y &= h_g(x_g)
\end{align*}

in which $x_g \in \bbR^{n_g}$ are the grey-box states, which are some subset of
the plant states (denote $x_g = Gx_p$) chosen to be modeled. The dynamics of
these grey-box states potentially have some missing terms in their ODEs. For
observable nonlinear systems, we can construct the original plant state using a
history of measurements and control inputs. Denote this history as 
\begin{align*}
  \mathbf{y}_{k-N_p:k-1} &= [y(k-N_p\Delta)', ... \ , y(k-\Delta)']' \\
  \mathbf{u}_{k-N_p:k-1} &= [u(k-N_p\Delta)', 
                               ... \ , u(k-\Delta)']'
\end{align*}

in which $N_p$ is the number of past measurements and $\Delta$ is the sample
time between two consecutive measurements. There exists a $\phi(\cdot)$ and a
number of delay time steps $N_p$, such that the plant state at a given time can
be written as $x_p(k) = \phi(\mathbf{y}_{k-N_p:k}, \mathbf{u}_{k-N_p:k-1})$. For
linear plants, this function $\phi(\cdot)$ is known analytically in terms of the
plant dynamic matrices.

We augment the grey-box model using neural networks as follows -
\begin{align} \label{eq:hybrid_cont_time}
\dot x_g &= f_g(x_g, u) + 
f_N(x_g, z, u) \notag \\
y &= h_g(x_g) 
\end{align}
in which $f_N(\cdot)$ is a feedforward neural network and $z(k) =
[\mathbf{y}'_{k-N_p:k-1}, \mathbf{u}'_{k-N_p:k-1}]'$. This model is converted to
discrete-time using the Runge-Kutta 4 method, and the vector of past controls
and measurements ($z$) is also viewed as a state. The discrete-time model is
represented as 
\begin{equation} \label{eq:hybrid_discrete_time}
  \begin{split}
    x_g^+ &= f_h(x_g, z, u)  \\
    z^+ &= f_z(z, x_g, u) \\
    y &= h_g(x_g)       
  \end{split}
\end{equation}
in which, $f_h(\cdot)$ is a obtained by discretization of
\eqref{eq:hybrid_cont_time} using the Runge-Kutta 4 method, and $f_z$ is known
analytically.

A few alternative modeling choices are:
\begin{itemize}
	\item Black-box: $y^+ = f_N(y, z, u)$, (purely black-box)
  \item Hybrid 1: $x_g^+ = f_N(x_g, z, u), \ z^+ = f_z(z, x_g, u), \ y =
                   h_g(x_g)$, (states have meaning)
  \item Hybrid 2: $x_g^+ = f_g(x_g, u), \ z^+ = f_z(z, x_g, u), \ y = h_g(x_g) +
                   h_N(z)$, (model residual)
  \item Hybrid 3: $\dot x_g = f_g(x_g, u, p(h_g(x_g), z)), \ z^+ = f_z(z, x_g,
  u), \ y = h_g(x_g)$, (use NNs to learn some parameters)
\end{itemize}

\subsection{Conversion to discrete time and training}
We note that the network $f_N(\cdot)$ is an addition to the grey-box dynamics in
continuous time in \eqref{eq:hybrid_cont_time}. The Runge-Kutta-4 (RK4) method
is used for the discretization as follows

\begin{align*}
  k_1 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k-N_p:k-1}, \mathbf{u}_{k-N_p:k-1}, u) \\
  x_g & := x_g + (\Delta/2)k_1 \\
  k_2 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+0.5-N_p:k-0.5}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g & := x_g + (\Delta/2)k_2 \\
  k_3 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+0.5-N_p:k-0.5}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g & := x_g + \Delta k_3 \\
  k_4 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+1-N_p:k}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g(k+\Delta) &= x_g(k) + (\Delta/6)(k_1 + 2k_2 + 2k_3 + k_4) \\
  \hat{y}(k+\Delta) &= h_g(x_g(k+\Delta)) 
\end{align*}
in which the sequence $\mathbf{y}_{k+0.5-N_p:k-0.5}$ is obtained by linear
interpolation.

The following optimization problem is solved to compute the weights in the
neural network
\begin{align*}
\underset{W_i, b_i}{\textnormal{min}} \sum_{k=0}^{N_s-1} 
\dfrac{1}{2}(\hat{y}(k) - y(k))^2
 \end{align*}
in which $W_i$, $b_i$ are the weights in each hidden layer of the NN, $N_s$ is
the number of training samples, $\hat{y}$ are the predictions of the augmented
grey-box + neural network model, and $y$ are the measurements from the plant.
Note that this optimization requires an estimate of the initial grey-box state.
We assume that before the open-loop system identification experiment performed
for data collection, the plant is being operated at some steady-state such that
input to output responses of the plant and grey-box model are aligned with the
use of an integrating disturbance model. We can use the grey-box state at that
steady state as the initial condition for the above multi-step-ahead
prediction-error optimization.

\subsection{Nonlinear reactor example}
We consider a nonlinear reactor with two reactions ($A \rightarrow B $ and  $3B
\rightleftharpoons C$), simulated using the following ordinary differential
equations (ODEs)
\begin{align*}
  \dfrac{dC_A}{dt} &= \dfrac{C_{Af} - C_A}{\tau} - k_1C_A\\
  \dfrac{dC_B}{dt} &= k_1C_A - 3k_2C^3_B + 3k_3C_C- \dfrac{C_B}{\tau}\\
  \dfrac{dC_C}{dt} &= k_2C^3_B - k_3C_C - \dfrac{C_C}{\tau}
\end{align*}

The grey-box model is chosen as follows with an assumption that knowledge of the
second side reaction ($3B \rightleftharpoons C $) is not available
\begin{align*}
  \dfrac{dC_A}{dt} &= \dfrac{C_{Af} - C_A}{\tau} - k_1C_A\\
  \dfrac{dC_B}{dt} &= k_1C_A - \dfrac{C_B}{\tau}
\end{align*}
The control input is $u = C_{Af}$, the states in the plant model are $x = [C_A,
C_B, C_C]'$, and the measurements are $y = [C_A, C_B]'$. We assume the following
parameters values, $k_1 = 1 \ \textnormal{m}^3/\textnormal{min}, \ k_2 = 0.01 \
\textnormal{m}^3/\textnormal{min}, \ k_3 = 0.05 \
\textnormal{m}^3/\textnormal{min}$, and $\tau = 5 \ \textnormal{min}$.

We examine the performance of the hybrid modeling framework
\eqref{eq:hybrid_discrete_time} in simulation studies. First, we generate
training data by simulating the plant model using a pseudo-random-binary-signal
(PRBS) manipulated input profile. Second, we train a black-box neural network
and the hybrid model \eqref{eq:hybrid_discrete_time} with network architectures
of [9, 16, 2] and [8, 16, 2]. Third, we examine trained model predictions and a
mean squared error (MSE) performance metric on validation data generated using
the plant model. Finally, we analyze the steady state cost curves obtained using
the trained models and their differences with the steady state cost 
curve of the plant model. These
simulations and analysis shed light on the data requirements of the hybrid and black-box
modeling frameworks, and enable an understanding of their performance if used
for real-time economic optimization in chemical plants.

\begin{figure}[!h]
  \centering
  \includegraphics[page=2, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Model validation for the non linear plant}
  \label{fig:validation_nonlinear}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[page=3, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Steady state cost curve for the nonlinear plant, grey-box, black-box,
  residual, and hybrid model after training with 5 hours of data.}
  \label{fig:cost_nonlinear_5hours}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[page=4, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Steady state cost curve for the nonlinear plant, grey-box, black-box,
  residual, and hybrid model after training with 10 hours of data.}
  \label{fig:cost_nonlinear_10hours}
\end{figure}

%\begin{figure}[!h] \centering \includegraphics[page=1,
%  width=\textwidth]{tworeac_distmodels_nonlin.pdf} \caption{Steady state
%  grey-box states and disturbance estimates based on output and input
%  disturbance models} \label{fig:cost_nonlinear_10hours} \end{figure}


\end{document}
