\documentclass{article}
\usepackage[total={6in, 8in}]{geometry}
%% The graphicx and color packages should give you all the color,
%% figure inclusion, and text/figure resizing capabilities you need.
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz,tikzsettings,bm}
\usepackage{almostfull}

\definecolor{pblue}{HTML}{1F77B4}
\definecolor{pgold}{HTML}{FF7f0E}
\definecolor{pgreen}{HTML}{2CA02C}
\definecolor{pred}{HTML}{D62728}
\definecolor{ppurple}{HTML}{9467BD}
\definecolor{ppink}{HTML}{E377C2}
\definecolor{pyellow}{HTML}{BCBD22}
\definecolor{pcyan}{HTML}{17BECF}

\usepackage{authblk}

%% You should not need more than this for fancy math.
\usepackage{amsmath}   % Extra math commands and environments from the AMS
\usepackage{amssymb}   % Special symbols from the AMS
\usepackage{amsthm}    % Enhanced theorem and proof environments from the AMS
\usepackage{latexsym}  % A few extra LaTeX symbols

\usepackage{lucidbry}
\input{stanacce}
\renewcommand{\baselinestretch}{1.0666}

%% The URL package is handy for typesetting URLs.  It does not define
%% an \email command because so many document styles already do that.
%% So we define one here that uses a typewriter font.
\usepackage{url}
%\DeclareRobustCommand{\email}{\begingroup \urlstyle{tt}\Url}
\providecommand{\email}{}
\renewcommand{\email}[1]{\texttt{#1}}

%% This provides various customized verbatim commands and
%% environments.  You probably don't need it.
\usepackage{fancyvrb}
\DefineShortVerb{\|}
\VerbatimFootnotes
\DefineVerbatimEnvironment{code}{Verbatim}{%
  frame=single,
  framesep=1em,
  xleftmargin=1em,
  xrightmargin=1em,
  samepage=true,
  fontsize=\footnotesize}
\usepackage{upquote}

%% Your document may require a different bibliography style.  I've
%% come to prefer Author (YYYY) styles because it makes it easier for
%% a person who knows something about the literature to understand
%% what is being cited without having to skip to the list of
%% references.
\usepackage[authoryear,round,longnamesfirst]{natbib}

%% You won't normally need this definition in your documents, but it
%% is here so we can typeset the BibTeX logo correctly.
\makeatletter
\@ifundefined{BibTeX}
   {\def\BibTeX{{\rmfamily B\kern-.05em%
    \textsc{i\kern-.025em b}\kern-.08em%
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}}{}

\def\blfootnote{\xdef\@thefnmark{}\@footnotetext}
\makeatother

%% Allow more of the pages to be occupied by graphs.  These parameters
%% are described in section c.9.1 of the LaTeXbook.  Your document may
%% not benefit from these parameters (it could make things worse) so
%% you should only change these from the defaults if you need to.
\setcounter{topnumber}{2}              %% 2
\setcounter{bottomnumber}{1}           %% 1
\setcounter{totalnumber}{3}            %% 3
\renewcommand{\topfraction}{0.9}       %% 0.7
\renewcommand{\bottomfraction}{0.9}    %% 0.3
\renewcommand{\textfraction}{0.1}      %% 0.2
\renewcommand{\floatpagefraction}{.7}  %% 0.5
\newlength{\graphwidth}
\setlength{\graphwidth}{0.8\columnwidth}

\usepackage{subfiles}

\graphicspath{{./}{./figures/}{./figures/paper/}}

\newcommand{\Is}{\bm{\mathrm{I}}} % Resources.
\newcommand{\Js}{\bm{\mathrm{J}}} % Units.
\newcommand{\Ks}{\bm{\mathrm{K}}} % Resources.
\newcommand{\Ms}{\bm{\mathrm{M}}} % Transition catalog.
\newcommand{\Ns}{\bm{\mathrm{N}}} % Transition counter.

\newcommand{\useq}{\mathbf{u}}
\newcommand{\xseq}{\mathbf{x}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbP}{\mathbb{P}}

\title{Hybrid nonlinear system identification using neural networks}
\author{Pratyush Kumar}
\date{\today}

\begin{document}

\maketitle

\section{Process modeling}
Consider a nonlinear plant evolving in continuous time as
\begin{align*}
  \dot{x}_p &= f_p(x_p, u, w) \\
  y &= h_p(x_p) + v
\end{align*}
in which $x_p \in \bbR^{n_p}$ is the plant state, 
$u \in \bbU$ is the manipulated control input,
$y \in \bbR^p$ is the measurement, $w$ is the process noise, 
and $v$ is the measurement noise.

\subsection{Completion of the u-y model}
We assume that grey-box modeling is performed 
for the plant, and we wish to augment the grey-box model with neural networks
for improvement in the accuracy of the model. From first-principles modeling, 
we have the following grey-box model in continuous time
\begin{align*}
  \dot{x}_g &= f_g(x_g, u) \\
  y &= h_g(x_g)
\end{align*}

in which $x_g \in \bbR^{n_g}$ are the grey-box states, 
which are some subset 
of the plant states (denote $x_g = Gx_p$) chosen to 
be modeled. The dynamics of these grey-box states 
potentially have some missing terms 
in their ODEs.
For observable nonlinear systems, 
we can construct the original plant state
using a history of measurements and control inputs.
Denote this history as 
\begin{align*}
  \mathbf{y}_{k-N_p:k-1} &= [y(k-N_p\Delta)', ... \ , y(k-\Delta)']' \\
  \mathbf{u}_{k-N_p:k-1} &= [u(k-N_p\Delta)', 
                               ... \ , u(k-\Delta)']'
\end{align*}

in which $N_p$ is the number of 
past measurements and
$\Delta$ is the sample time between two consecutive
measurements. There exists a $\phi(\cdot)$ 
and a number of delay 
time steps $N_p$, such that the plant state
at a given time can be written as
$x_p(k) = \phi(\mathbf{y}_{k-N_p:k}, \mathbf{u}_{k-N_p:k-1})$.
For linear plants, this function $\phi(\cdot)$
is known analytically in terms of the plant dynamic
matrices.

We augment the grey-box model using
neural networks as follows -
\begin{align} \label{eq:hybrid_cont_time}
\dot x_g &= f_g(x_g, u) + 
f_N(x_g, z, u) \notag \\
y &= h_g(x_g) 
\end{align}
in which $f_N(\cdot)$ is a feedforward neural network
and $z(k) = [\mathbf{y}'_{k-N_p:k-1}, \mathbf{u}'_{k-N_p:k-1}]'$.
This model is converted to discrete-time using the 
Runge-Kutta 4 method, and the vector of past controls
and measurements ($z$) is also viewed as a state. The discrete-time 
model is represented as 
\begin{align*}
  x_g^+ &= f_h(x_g, z, u) \\
  z^+ &= f_z(z, x_g, u)\\
  y &= h_g(x_g) 
\end{align*}
in which, $f_h(\cdot)$ is a obtained by discretization
of \eqref{eq:hybrid_cont_time} using the Runge-Kutta 4 method, 
and $f_z$ is known analytically.

A few alternative modeling choices are:
\begin{itemize}
	\item Black-box: $y^+ = f_N(y, z, u)$, (purely black-box)
  \item Hybrid 1: $x_g^+ = f_N(x_g, z, u), 
                   \ z^+ = f_z(z, x_g, u), \ y = h_g(x_g)$, 
  (states have meaning)
  \item Hybrid 2: $x_g^+ = f_g(x_g, u), 
                   \ z^+ = f_z(z, x_g, u), \ y = h_g(x_g) + h_N(z)$, 
	(model residual)
  \item Hybrid 3: $\dot x_g = f_g(x_g, u, p(h_g(x_g), z)),
  \ z^+ = f_z(z, x_g, u), \ y = h_g(x_g)$, (use NNs to learn some parameters)
\end{itemize}

%It is expected that the functions $f_{NN}(\cdot)$ 
%and $h_{NN}(\cdot)$ approximate
%the following differences between the true grey-box state dynamics
%and true measurement function with what is modeled.
%\begin{align*}
%  f_{NN}(\mathbf{y}_{k+1-N_p:k}, \mathbf{u}_{k+1-N_p:k}) &\approx 
%      Gf_p(x, u) - f_g(Gx, u) \\
%      h_{NN}(\mathbf{y}_{k+1-N_p:k}, \mathbf{u}_{k+1-N_p:k-1}) &\approx
%      h_p(x) - h_g(Gx) 
%\end{align*}  
%in which $x(k) = \phi(\mathbf{y}_{k+1-N_p:k}, \mathbf{u}_{k+1-N_p:k-1})$
%is an unknown function of past measurements and inputs.

\subsection{Conversion to discrete time and training}
We note that the network $f_N(\cdot)$ is an addition 
to the grey-box dynamics in continuous time in \eqref{eq:hybrid_cont_time}. 
The Runge-Kutta-4 (RK4) method 
is used for the discretization as follows

\begin{align*}
  k_1 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k-N_p:k-1}, \mathbf{u}_{k-N_p:k-1}, u) \\
  x_g & := x_g + (\Delta/2)k_1 \\
  k_2 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+0.5-N_p:k-0.5}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g & := x_g + (\Delta/2)k_2 \\
  k_3 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+0.5-N_p:k-0.5}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g & := x_g + \Delta k_3 \\
  k_4 &= f_g(x_g, u) + 
  f_N(x_g, \mathbf{y}_{k+1-N_p:k}, \mathbf{u}_{k-N_p:k-1}, u)\\
  x_g(k+\Delta) &= x_g(k) + (\Delta/6)(k_1 + 2k_2 + 2k_3 + k_4) \\
  \hat{y}(k+\Delta) &= h_g(x_g(k+\Delta)) 
\end{align*}
in which the sequence $\mathbf{y}_{k+0.5-N_p:k-0.5}$ is obtained by 
linear interpolation.

The following optimization problem is solved to compute 
the weights in the neural network
\begin{align*}
\underset{W_i, b_i}{\textnormal{min}} \sum_{k=0}^{N_s-1} 
\dfrac{1}{2}(\hat{y}(k) - y(k))^2
 \end{align*}
in which $W_i$, $b_i$ are the weights in each hidden layer of the NN, 
$N_s$ is the number of training samples, 
$\hat{y}$ are the predictions of the augmented
grey-box + neural network model, and $y$
are the measurements from the plant.
Note that this optimization requires an estimate 
of the initial grey-box state. We assume that 
before the open-loop system identification experiment 
performed for data collection, 
the plant is being operated at some 
steady-state such that input to output
responses of the plant and grey-box model are aligned with 
the use of an integrating disturbance model. We can use 
the grey-box state at that steady state as the initial condition 
for the above multi-step-ahead prediction-error
optimization.

%\subsection{Linear plant}

%Consider the following plant, model,
%and the expected function to be approximated 
%with a neural network.

%\textbf{Plant --}
%\begin{align*}
%  \dfrac{dC_A}{dt} &= \dfrac{C_{Af} - C_A}{\tau} - k_1C_A\\
%  \dfrac{dC_B}{dt} &= k_1C_A - k_2C_B + k_3C_C- \dfrac{C_B}{\tau}\\
%  \dfrac{dC_C}{dt} &= k_2C_B - k_3C_C - \dfrac{C_C}{\tau}
%\end{align*}
%These ODEs represent the dynamics of the reaction system
%$A \rightarrow B \rightleftharpoons C$ in a CSTR with constant 
%height and temperature. The control input is $u = C_{Af}$,
%the states are $x = [C_A, C_B, C_C]'$, 
%and the measurements are $y = [C_A, C_B]'$. 
%Assume the following 
%parameters for this model, $k_1 = 1 \ \textnormal{m}^3/\textnormal{min}, 
%\ k_2 = 0.3 \ \textnormal{m}^3/\textnormal{min},
%\ k_3 = 0.2 \ \textnormal{m}^3/\textnormal{min}$, 
%and $\tau = 5 \ \textnormal{min}$.
%The plant model 
%is linear ($dx/dt = Ax + Bu$) and 
%observable with the choices of 
%the parameters and measurements.

%\textbf{Model --}
%\begin{align*}
%  \dfrac{dC_A}{dt} &= \dfrac{C_{Af} - C_A}{\tau} - k_1C_A\\
%  \dfrac{dC_B}{dt} &= k_1C_A - \dfrac{C_B}{\tau}
%\end{align*}
%i.e, we assume that we don't know about the second reaction while 
%performing grey-box modeling. 

%The current plant state $x_p(k)$ can be constructed using the history of 
%past measurements and inputs as 
%\begin{equation*}
%  x_p(k) = A^{N_p-1}_d
%  \mathcal{O}^{\dagger}(\mathbf{y}_{k+1-N_p:k} - 
%                        \mathcal{B}\mathbf{u}_{k+1-N_p:k-1}) + \\ 
%      \mathcal{B}_{nN_p-n+1:nN_p}\mathbf{u}_{k+1-N_p:k-1}
%\end{equation*}

%in which $A_d$ is the plant state transition matrix in discrete-time, 
%$\mathcal{O}$ is the observability matrix, 
%and $\mathcal{B}$ is a combination of the 
%discrete time matrices ($A_d$ and $B_d$) such that it 
%denotes the response of a vector of inputs to states, 
%and $\mathcal{B}_{nN_p-n+1:nN_p}$ denotes the last $n$
%rows of $\mathcal{B}$.

%Since the measurements are a simple linear function 
%of the grey-box and plant states, we use only one 
%neural network to 
%augment the grey-box dynamics. 
%The expected function 
%to be approximated with the network is
%\begin{align*}
%  f_N(\mathbf{y}_{k-N_p:k}, \mathbf{u}_{k+1-N_p:k-1}) \approx 
%  \begin{bmatrix}
%  0 & 0 & 0 \\  
%  0 & -k_2 & k_3 
%  \end{bmatrix}x_p(k)
%\end{align*}

%In this example, the network just approximates a linear function.
%The Figure \ref{fig:validation_linear} 
%below shows validation performances of the grey-box 
%and augmented hybrid models. The structure 
%of the network is restricted to just a matrix and
%the augmented model was trained on 240 samples (4 hours).

%THe Figures \ref{fig:cost_nonlinear_5hours} and 
%\ref{fig:cost_nonlinear_5hours} 

%\begin{figure}[!h]
%  \centering
%  \includegraphics[page=2, width=\textwidth]{tworeac_plots_lin.pdf}
%  \caption{Model validation for the linear plant}
%  \label{fig:validation_linear}
%\end{figure}

%We notice that the augmented model accurately predicts the plant 
%behavior. The steady cost profile (Cost = $c_1C_{Af} - c_2C_B$)
%is shown in Figure \ref{fig:cost_linear}. 

%\begin{figure}[!h]
%  \centering
%  \includegraphics[page=3, width=\textwidth]{tworeac_plots_lin.pdf}
%  \caption{Steady state cost curve for 
%           the linear plant, grey-box, and hybrid model.}
%  \label{fig:cost_linear}
%\end{figure}

\subsection{Nonlinear reactor example}
We consider a nonlinear reactor with 
two reactions ($A \rightarrow B $ and  $3B \rightleftharpoons C$),
simulated with the following ODEs
\begin{align*}
  \dfrac{dC_A}{dt} &= \dfrac{C_{Af} - C_A}{\tau} - k_1C_A\\
  \dfrac{dC_B}{dt} &= k_1C_A - 3k_2C^3_B + 3k_3C_C- \dfrac{C_B}{\tau}\\
  \dfrac{dC_C}{dt} &= k_2C^3_B - k_3C_C - \dfrac{C_C}{\tau}
\end{align*}

The grey-box model is kept the same. The parameters 
in the model are modified to 
$k_1 = 1 \ \textnormal{m}^3/\textnormal{min}, 
\ k_2 = 0.01 \ \textnormal{m}^3/\textnormal{min},
\ k_3 = 0.05 \ \textnormal{m}^3/\textnormal{min}$, 
and $\tau = 5 \ \textnormal{min}$.

\newpage
Three models are compared: black-box, residual, and hybrid model with additive 
NN to the grey-box dynamics. The chosen model architectures 
are [9, 16, 16, 2], [9, 16, 16, 2], and [8, 16, 2] respectively.
The Figure \ref{fig:validation_nonlinear} shows model validation on open loop 
data after training with 10 hours of data.

The Figures \ref{fig:cost_nonlinear_5hours} and \ref{fig:cost_nonlinear_10hours}
show the steady state cost curve after training with 5 and 10 hours 
of data respectively. We notice that the hybrid model is more data efficient 
compared to the alternatives.

\begin{figure}[!h]
  \centering
  \includegraphics[page=2, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Model validation for the non linear plant}
  \label{fig:validation_nonlinear}
\end{figure}

%We notice that the augmented model accurately predicts the plant 
%behavior. The steady cost profile (Cost = $c_1C_{A0} - c_2C_B$)
%is shown in Figure \ref{fig:cost_nonlinear}. Upon optimization 
%using casadi, the optimum cost and control for the plant are: $-19.62 \$$ 
%and 1.13 $\textnormal{mol}/\textnormal{m}^3$, and for the hybrid 
%grey-box and NN model are: $-19.91 \$$ 
%and 1.11 $\textnormal{mol}/\textnormal{m}^3$.


\begin{figure}[!h]
  \centering
  \includegraphics[page=3, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Steady state cost curve for the nonlinear plant, grey-box, 
  black-box, residual, and hybrid model after training with 5 hours of data.}
  \label{fig:cost_nonlinear_5hours}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[page=4, width=\textwidth]{tworeac_plots_nonlin.pdf}
  \caption{Steady state cost curve for the nonlinear plant, grey-box, 
  black-box, residual, and hybrid model after training with 10 hours of data.}
  \label{fig:cost_nonlinear_10hours}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[page=1, width=\textwidth]{tworeac_distmodels_nonlin.pdf}
  \caption{Steady state grey-box states and disturbance estimates based on 
  output and input disturbance models}
  \label{fig:cost_nonlinear_10hours}
\end{figure}

%\textbf{Need to discuss the following issues:}
%\begin{itemize}
%  \item What are the example problems/applications 
%  where both kind of modeling 
%  strategies make sense, and where should we start.
%  Reproduce results from the Kevrekidis paper with measurement 
%  noise?
%  \item The model training step will be the optimization of 
%  the following multi-step-ahead prediction-error
%  \begin{equation*}
%    \underset{W_i, b_i}{\textnormal{min}} \sum_{k=0}^{t-1} (\hat{y}(k) - y(k))^2
%  \end{equation*}
%  in which ($W_i, b_i$) are the weights of the NN. This optimization 
%  is for one ID experiment, and requires an initial grey-box 
%  state $x_g(0)$ to make the forecast. If we have data 
%  for multiple ID experiments, we'll need initial states for 
%  all the ID experiments. In theory, we can add the initial 
%  states as decision variables in the optimization, but 
%  unfortunately tensorflow 
%  does not has a mechanism to do this.
%\end{itemize}

%\subsection{Adding feedforward disturbance forecasts}
%In this class of problems, we assume that we have a pretty 
%good u-y model from first-principles knowledge, and we'll use 
%neural networks to make feedforward disturbance forecasts
%for use in online MPC. HVAC is a pretty good application.

%\section{Optimization in MPC with neural networks as model}
%This is probably a late fall quarter or a winter break project. \\
%a) Try Casadi/MPC tools. 
%If tanh is the activation function (optimization is smooth),
%this should be fine. \\
%b) Try a global optimization solver. \\
%c) Train another NN with solutions from a global optimization solver.

\end{document}
