\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{authblk}
\usepackage{amssymb}
%\usepackage{lucidbry}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{subcaption}
\usepackage{physics}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz,tikzsettings}
\usepackage{verbatim}
\usetikzlibrary{arrows,shapes}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{float}
\usepackage[round]{natbib}
\usepackage[english]{babel}
\bibliographystyle{plainnat}
%\setcitestyle{numeric,open={(},close={)}} \usepackage{color}
%\usepackage{colortbl}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{shapes,calc,backgrounds,arrows,fit,decorations.pathmorphing,matrix}
\usepackage[margin=0.79in]{geometry}

\graphicspath{{./}{./figures/}{./figures/paper/}}

\newcommand{\Is}{\bm{\mathrm{I}}} % Resources.
\newcommand{\Js}{\bm{\mathrm{J}}} % Units.
\newcommand{\Ks}{\bm{\mathrm{K}}} % Resources.
\newcommand{\Ms}{\bm{\mathrm{M}}} % Transition catalog.
\newcommand{\Ns}{\bm{\mathrm{N}}} % Transition counter.

\newcommand{\useq}{\mathbf{u}} \newcommand{\xseq}{\mathbf{x}}
\newcommand{\bbR}{\mathbb{R}} \newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbU}{\mathbb{U}} \newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbX}{\mathbb{X}} \newcommand{\bbP}{\mathbb{P}}

\title{Black-box system identification using neural networks and Koopman operators}
\author{Pratyush Kumar}
\date{\today}

\begin{document}

\maketitle

\section{Process modeling}
Consider a nonlinear plant evolving in continuous time as
\begin{align*}
  \dot{x}_p &= f_p(x_p, u, w) \\
  y &= h_p(x_p) + v
\end{align*}
in which $x_p \in \bbR^{n_p}$ is the plant state, $u \in \bbU$ is the
manipulated control input, $y \in \bbR^p$ is the measurement, $w$ is the process
noise, and $v$ is the measurement noise.

\subsection{Neural network model}
First, we model the input-output relationship of the plant using a black-box
neural network that uses past control inputs and measurements to predict the
future measurements of the plant. We denote this past history as follows:
\begin{align*}
  \mathbf{y}_{k-N_p:k-1} &= [y(k-N_p)', ... \ , y(k-1)']' \\
  \mathbf{u}_{k-N_p:k-1} &= [u(k-N_p)', ... \ , u(k-1)']' \\
  z(k) &= [\mathbf{y}_{k-N_p:k-1}', \mathbf{u}_{k-N_p:k-1}']'
\end{align*}

in which $N_p$ is the number of past measurements and control inputs used. The
state of the dynamic model represented by the neural network is 
\begin{align*}
  x(k) &= [y(k)', z(k)']'
\end{align*}
and the overall model is
\begin{align*}
  x^+ = \begin{bmatrix}
    y^+ \\
    z^+
  \end{bmatrix} &= \begin{bmatrix}
    f_N(x, u) \\
    f_z(x)
  \end{bmatrix}, \quad y = \begin{bmatrix}
    I & 0
  \end{bmatrix}x
\end{align*}

\subsubsection{Training}
The training problem is to find the parameters in the neural network
$f_N$ by minimizing the following mean squared error:

\begin{align*}
  \underset{W_i, b_i}{\textnormal{min}} \sum_{k=0}^{N_t-1} 
  \dfrac{1}{N_t}(\hat{y}(k) - y(k))^2
\end{align*}

\subsection{Deep Koopman operator model}

Next, we study black-box linear system identification using neural networks as Koopman operators to lift the state-space in a higher dimensional space. The
state of the dynamic model is represented as follows
\begin{align*}
  x(k) &= [y(k)', z(k)']'
\end{align*}
and the overall model is
\begin{align*}
  x_{kp}^+ = Ax_{kp} + Bu, \quad x_{kp} = [x', f_N(x)']', \quad x = \begin{bmatrix}
    I & 0
  \end{bmatrix}x_{kp}, \quad y = \begin{bmatrix}
    I & 0
  \end{bmatrix}x
\end{align*}

\subsubsection{Training}
The training problem is to find the parameters in the neural network
$f_N$ and the linear model matrices $A$ and $B$ by minimizing the following mean squared error:

\begin{align*}
  \underset{A, B, W_i, b_i}{\textnormal{min}} \sum_{k=0}^{N_t-1} 
  \dfrac{1}{N_t}(\hat{x}(k) - x(k))^2
\end{align*}

\subsection{Encoder-Decoder Koopman operator model}

\begin{align*}
  x(k) &= [y(k)', z(k)']'
\end{align*}
The overall model is
\begin{align*}
  x_{kp}^+ = Ax_{kp} + Bu, \quad x_{kp} = f_{EN}(x), \quad x = f_{DN}(x_{kp}), \quad y = \begin{bmatrix}
    I & 0
  \end{bmatrix}x
\end{align*}

\subsubsection{Training}
The training problem is to find the parameters in the neural networks
$f_{EN}$, $f_{DN}$ and the linear model matrices $A$ and $B$ by minimizing the following mean squared error:

\begin{align*}
  \underset{A, B, W_i, b_i}{\textnormal{min}} \sum_{k=0}^{N_t-1} 
  \dfrac{1}{N_t}(\hat{x}(k) - x(k))^2
\end{align*}

\end{document}
